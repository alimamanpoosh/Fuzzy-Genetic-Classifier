{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_variable = \"linguistic variable\"\n",
    "Paramerters_S = \"S\"\n",
    "Paramerters_M = \"M\"\n",
    "type_Fuzzy_Set = \"fuzzy set\"\n",
    "rule = \"rule\"   \n",
    "structure = 'structure'\n",
    "being = 'being'\n",
    "not_list = 'not_list'\n",
    "term_choice = 'term_choice'\n",
    "\n",
    "Max_S = 70   # 2 * 35   # calcualte the database\n",
    "Min_S = 0\n",
    "Max_M = 7    # 2*5\n",
    "Min_M = -11  # 2*-5\n",
    "\n",
    "num_gen = 5\n",
    "linguistic = [\"very low\", \"low\", \"medium\", \"high\", \"very high\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chromosomes(num_chromosomes):\n",
    "    chromosomes = []\n",
    "    \n",
    "    for i in range(num_chromosomes):\n",
    "        chro = dict()\n",
    "        chro[structure] = []\n",
    "        for _ in range(num_gen):\n",
    "            gen = dict()\n",
    "            num_feature = random.randint(3, 5)\n",
    "            gen[linguistic_variable] = [random.choice(linguistic) for i in range(num_feature)]\n",
    "            gen[Paramerters_S] = [random.uniform(Min_S, Max_S) for i in range(num_feature)]\n",
    "            gen[Paramerters_M] = [random.uniform(Min_M, Max_M) for i in range(num_feature)]\n",
    "            gen[type_Fuzzy_Set] = [random.randint(1, 4) for i in range(num_feature)]\n",
    "            chro[structure].append(gen)\n",
    "        \n",
    "        gen_rule = dict()\n",
    "        gen_rule[being] = [random.choice([0, 1]) for i in range(num_gen)]     # 1 ==> be   0 ==> not be\n",
    "        gen_rule[not_list] = [random.choice([0, 1]) for i in range(num_gen)]  # 1 ==> NOT   0 == self\n",
    "        gen_rule[term_choice] = [random.choice(linguistic) for i in range(num_gen)]   # which term?\n",
    "        \n",
    "        chro[rule] = gen_rule  \n",
    "\n",
    "        chromosomes.append(chro)\n",
    "        \n",
    "        \n",
    "    return chromosomes\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a list of chromosomes.\n",
    "def create_chromosomes2(num_chromosomes):\n",
    "    # Initialize an empty list to store the chromosomes.\n",
    "    chromosomes = []\n",
    "    \n",
    "    # For each chromosome:\n",
    "    for i in range(num_chromosomes):\n",
    "        # Initialize an empty dictionary to store this chromosome's genetic material.\n",
    "        chro = dict()\n",
    "        chro[structure] = []\n",
    "        # For each genetic element (gene) in the chromosome:\n",
    "        for _ in range(num_gen):\n",
    "            # Initialize an empty dictionary to store this gene's features (linguistic variable, parameter S, parameter M, and type of fuzzy set).\n",
    "            gen = dict()\n",
    "            # Generate a random number between 3 and 5 to determine the number of linguistic variables in this feature.\n",
    "            num_feature = random.randint(3, 5)\n",
    "            # For each linguistic variable in this feature, randomly choose one from the set of possible linguistic variables and add it to the list of linguistic variables in this feature.\n",
    "            gen[linguistic_variable] = [random.choice(linguistic) for i in range(num_feature)]\n",
    "            # For each parameter S in this feature, randomly generate a floating-point number between Min_S and Max_S and add it to the list of S parameters in this feature.\n",
    "            gen[Paramerters_S] = [random.uniform(Min_S, Max_S) for i in range(num_feature)]\n",
    "            # For each parameter M in this feature, randomly generate a floating-point number between Min_M and Max_M and add it to the list of M parameters in this feature.\n",
    "            gen[Paramerters_M] = [random.uniform(Min_M, Max_M) for i in range(num_feature)]\n",
    "            # For each type of fuzzy set in this feature, randomly generate an integer between 1 and 4 and add it to the list of fuzzy set types in this feature.\n",
    "            gen[type_Fuzzy_Set] = [random.randint(1, 4) for i in range(num_feature)]\n",
    "            # Add the current gene (with its features) to this chromosome.\n",
    "            chro[structure].append(gen)\n",
    "        \n",
    "        # Initialize an empty dictionary to store the rule for this chromosome's genetic material.\n",
    "        gen_rule = dict()\n",
    "        # For each genetic element (gene) in the chromosome:\n",
    "        gen_rule[being] = [random.choice([0, 1]) for i in range(num_gen)]     # 1 ==> be   0 ==> not be\n",
    "        gen_rule[not_list] = [random.choice([0, 1]) for i in range(num_gen)]  # 1 ==> NOT   0 ==> self\n",
    "        gen_rule[term_choice] = [random.choice(linguistic) for i in range(num_gen)]   # which term?\n",
    "        # Add the rule to this chromosome.\n",
    "        chro[rule] = gen_rule  \n",
    "        # Add this chromosome (with its genetic material and rule) to the list of chromosomes.\n",
    "        chromosomes.append(chro)\n",
    "        \n",
    "    # Return the list of chromosomes.\n",
    "    return chromosomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'structure': [{'linguistic variable': ['very low', 'medium', 'very high', 'medium', 'very low'], 'S': [17.254077746771195, 44.62128726299758, 57.49500055822486, 11.993174375368408, 18.583050239284013], 'M': [-1.935493440394005, 2.5299479941510707, -9.319860695011092, 2.0023334129995263, -6.995560498602782], 'fuzzy set': [4, 1, 4, 3, 1]}, {'linguistic variable': ['medium', 'medium', 'very high', 'high', 'high'], 'S': [27.888843161146475, 6.029604359962317, 9.210164578857551, 51.42546773582088, 50.9110590586626], 'M': [0.4157590515591991, 0.9209975566179747, -0.9251200513774478, 3.577752938352292, -1.5547668025895458], 'fuzzy set': [1, 4, 3, 1, 3]}, {'linguistic variable': ['low', 'low', 'high', 'low', 'low'], 'S': [63.53149966170585, 62.43129150182224, 48.13340456654133, 53.553549372304495, 14.584669923265126], 'M': [-0.27715229795736285, -2.572016530537148, 5.356446932702049, -9.712240262252385, -10.376512233381547], 'fuzzy set': [4, 1, 1, 1, 1]}, {'linguistic variable': ['high', 'low', 'very low'], 'S': [32.383594075600406, 28.256412463948095, 49.687638496440684], 'M': [4.727952914268434, -10.148597797085166, -8.9939059549586], 'fuzzy set': [3, 1, 1]}, {'linguistic variable': ['high', 'very high', 'high'], 'S': [8.646726600846723, 1.3638531339971205, 19.01429707482364], 'M': [3.5407290571994334, -2.0159791076385503, -0.7945103488783527], 'fuzzy set': [2, 4, 1]}], 'rule': {'being': [0, 0, 0, 0, 1], 'not_list': [1, 1, 0, 1, 0], 'term_choice': ['high', 'high', 'high', 'very low', 'low']}}, {'structure': [{'linguistic variable': ['very low', 'low', 'very low', 'medium', 'high'], 'S': [19.924091552716742, 23.532740683305065, 38.53112507271495, 13.08092624465417, 47.41322291514384], 'M': [-4.143425973017118, -4.146658030944826, -8.0584955543965, 4.303183673355651, -0.5510510850974377], 'fuzzy set': [4, 4, 4, 1, 4]}, {'linguistic variable': ['low', 'medium', 'low', 'medium'], 'S': [12.173692335579778, 15.605601037578916, 0.04064379336595647, 64.52191329684892], 'M': [-4.944898493236356, 2.262244903264728, -6.935323937031265, -4.949869790398439], 'fuzzy set': [4, 1, 2, 2]}, {'linguistic variable': ['very high', 'medium', 'very high', 'low', 'medium'], 'S': [36.034536276749456, 41.996320698795365, 0.579572054161972, 64.78818924425828, 14.87926626772985], 'M': [6.6426849030961606, 3.947299444480276, -5.0635521030832376, -8.500893214391816, -4.712409463284887], 'fuzzy set': [2, 1, 2, 1, 1]}, {'linguistic variable': ['low', 'very high', 'very high', 'low', 'high'], 'S': [65.65077378320291, 53.78495566522395, 26.545935204060925, 14.662370191639319, 51.008078069511924], 'M': [-5.4200059884608125, -4.284635562185321, -5.91624129801027, 1.034363482586551, -3.4443513821975005], 'fuzzy set': [3, 3, 3, 3, 2]}, {'linguistic variable': ['very low', 'very high', 'high', 'very high', 'very low'], 'S': [65.93512443116649, 3.1263436685234214, 32.247903169883315, 57.186043953714886, 65.37824816050906], 'M': [-9.192906450819972, 5.489749391671584, 5.870801854468912, 4.58744200726583, 5.296290492976453], 'fuzzy set': [1, 4, 4, 2, 3]}], 'rule': {'being': [1, 0, 1, 1, 1], 'not_list': [1, 1, 1, 0, 0], 'term_choice': ['very high', 'very low', 'low', 'very low', 'very low']}}]\n",
      "[17.254077746771195, 44.62128726299758, 57.49500055822486, 11.993174375368408, 18.583050239284013]\n",
      "[27.888843161146475, 6.029604359962317, 9.210164578857551, 51.42546773582088, 50.9110590586626]\n"
     ]
    }
   ],
   "source": [
    "chro = create_chromosomes2(2)\n",
    "print(chro)\n",
    "# print(chro[0][structure][0][linguistic_variable])\n",
    "# print(chro[1][structure][0])\n",
    "\n",
    "parent1 = chro[0]\n",
    "parent2 = chro[1]\n",
    "\n",
    "print(chro[0][structure][0][Paramerters_S])\n",
    "print(chro[0][structure][1][Paramerters_S])\n",
    "# print(parent1)\n",
    "# print(parent2)\n",
    "# parent1_linguistic = chro[0][structure][0][linguistic_variable]\n",
    "# parent2_linguistic = chro[1][structure][0][linguistic_variable]\n",
    "\n",
    "# parent1_S = chro[0][structure][0][Paramerters_S]\n",
    "# parent2_S = chro[1][structure][0][Paramerters_S]\n",
    "\n",
    "# parent1_M = chro[0][structure][0][Paramerters_M]\n",
    "# parent2_M = chro[1][structure][0][Paramerters_M]\n",
    "\n",
    "# parent1_fuzzy = chro[0][structure][0][type_Fuzzy_Set]\n",
    "# parent2_fuzzy = chro[1][structure][0][type_Fuzzy_Set]\n",
    "\n",
    "# parent1_bein = chro[0][rule][being]\n",
    "# parent2_bein = chro[1][rule][being]\n",
    "\n",
    "# parent1_not_list = chro[0][rule][not_list]\n",
    "# parent2_not_list = chro[1][rule][not_list]\n",
    "\n",
    "# parent1_term_choice = chro[0][rule][term_choice]\n",
    "# parent2_term_choice = chro[1][rule][term_choice]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 16 (2284234988.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[71], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    offspring1.append(parent1[temp[i]])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def crossover_continuous2(parent1, parent2):    #پیوسته\n",
    "    alpha = 0.25\n",
    "    if len(parent1) > len(parent2):\n",
    "        indexes = [random.randint(0, 4) % 5 for i in range(len(parent2))]\n",
    "        for i in range(len(parent2)):\n",
    "            if parent2[i] > parent1[indexes[i]]:\n",
    "                distance = parent2[i] - parent1[indexes[i]]\n",
    "                offspring1.append(parent1[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent2[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent1[indexes[i]] - parent2[i]\n",
    "                offspring1.append(parent2[i] + alpha * distance)\n",
    "                offspring2.append(parent1[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        temp = [item for item in [0, 1, 2 , 3, 4] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "        offspring1.append(parent1[temp[i]])\n",
    "        \n",
    "    else:\n",
    "        indexes = [random.randint(0, 4) % 5 for i in range(len(parent1))]\n",
    "        for i in range(len(parent1)):\n",
    "            if parent1[i] > parent2[indexes[i]]:\n",
    "                distance = parent1[i] - parent2[indexes[i]]\n",
    "                offspring1.append(parent2[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent1[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent2[indexes[i]] - parent1[i]\n",
    "                offspring1.append(parent1[i] + alpha * distance)\n",
    "                offspring2.append(parent2[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        temp = [item for item in [0, 1, 2 , 3, 4] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "        offspring2.append(parent2[temp[i]])\n",
    "    \n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in two parents (sequences) and creates two offsprings by performing a continuous crossover.\n",
    "def crossover_continuous(parent1, parent2):    \n",
    "    # Set the alpha value for the crossover.\n",
    "    alpha = 0.25\n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    # If the first sequence is longer than the second one:\n",
    "    if len(parent1) > len(parent2):\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent1)), len(parent2))\n",
    "        # For each index in the shorter parent: if the corresponding element in the longer parent is greater, perform a crossover calculation using alpha and add the results to offspring1 and offspring2. Otherwise, perform the calculation using the reverse order and add the results to offspring1 and offspring2.\n",
    "        for i in range(len(parent2)):\n",
    "            if parent2[i] > parent1[indexes[i]]:\n",
    "                distance = parent2[i] - parent1[indexes[i]]\n",
    "                offspring1.append(parent1[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent2[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent1[indexes[i]] - parent2[i]\n",
    "                offspring1.append(parent2[i] + alpha * distance)\n",
    "                offspring2.append(parent1[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        # Add the remaining elements of the longer parent to the first offspring.     \n",
    "        temp = [item for item in [_ for _ in range(len(parent2))] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "            offspring1.append(parent1[temp[i]])\n",
    "        \n",
    "    # If the second sequence is longer than or the same length as the first one:\n",
    "    else:\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent2)), len(parent1))\n",
    "        # For each index in the shorter parent: if the corresponding element in the longer parent is greater, perform a crossover calculation using alpha and add the results to offspring1 and offspring2. Otherwise, perform the calculation using the reverse order and add the results to offspring1 and offspring2.\n",
    "        for i in range(len(parent1)):\n",
    "            if parent1[i] > parent2[indexes[i]]:\n",
    "                distance = parent1[i] - parent2[indexes[i]]\n",
    "                offspring1.append(parent2[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent1[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent2[indexes[i]] - parent1[i]\n",
    "                offspring1.append(parent1[i] + alpha * distance)\n",
    "                offspring2.append(parent2[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        # Add the remaining elements of the longer parent to the second offspring. \n",
    "        temp = [item for item in [_ for _ in range(len(parent2))] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "            offspring2.append(parent2[temp[i]])\n",
    "    \n",
    "    # Return the two new offspring.\n",
    "    return offspring1, offspring2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_discrete2(parent1, parent2):   # گسسته\n",
    "    #indexes = []\n",
    "    if len(parent1) > len(parent2):\n",
    "        indexes = [random.randint(0,4) % len(parent2) for i in range(len(parent2))]\n",
    "        for i in range(len(parent1)):\n",
    "            if i in indexes:\n",
    "                offspring2.append(parent1[i])\n",
    "            else:\n",
    "                offspring1.append(parent1[i])\n",
    "        offspring1.extend(parent2)     \n",
    "    else:\n",
    "        indexes = [random.randint(0,4) % len(parent1) for i in range(len(parent1))]\n",
    "        for i in range(len(parent2)):\n",
    "            if i in indexes:\n",
    "                offspring1.append(parent2[i])\n",
    "            else:\n",
    "                offspring2.append(parent2[i])\n",
    "        offspring2.extend(parent1)  \n",
    "    \n",
    "    #print(indexes)\n",
    "    return offspring1, offspring2 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in two parents (sequences) and creates two offsprings by performing a discrete crossover.\n",
    "def crossover_discrete(parent1, parent2):   \n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    # If the first sequence is longer than the second one:\n",
    "    if len(parent1) > len(parent2):\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent1)), len(parent2))\n",
    "        # For each index in parent1: if it's in indexes, add the corresponding element to offspring2. Otherwise, add it to offspring1. \n",
    "        for i in range(len(parent1)):\n",
    "            if i in indexes:\n",
    "                offspring2.append(parent1[i])\n",
    "            else:\n",
    "                offspring1.append(parent1[i])\n",
    "        # Add all of parent2 to offspring1.\n",
    "        offspring1.extend(parent2)     \n",
    "    # If the second sequence is longer than or the same length as the first one:\n",
    "    else:\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent2)), len(parent1))\n",
    "        # For each index in parent2: if it's in indexes, add the corresponding element to offspring1. Otherwise, add it to offspring2. \n",
    "        for i in range(len(parent2)):\n",
    "            if i in indexes:\n",
    "                offspring1.append(parent2[i])\n",
    "            else:\n",
    "                offspring2.append(parent2[i])\n",
    "        # Add all of parent1 to offspring2.\n",
    "        offspring2.extend(parent1)\n",
    "    \n",
    "    # Return the two new offspring.\n",
    "    return offspring1, offspring2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2):\n",
    "    structure1 = [dict() for i in range(num_gen)]\n",
    "    structure2 = [dict() for i in range(num_gen)]\n",
    "    \n",
    "    for i in range(num_gen):\n",
    "        structure1[i][linguistic_variable], structure2[i][linguistic_variable] = crossover_discrete(parent1[structure][i][linguistic_variable], parent2[structure][i][linguistic_variable])\n",
    "        structure1[i][type_Fuzzy_Set], structure2[i][type_Fuzzy_Set] = crossover_discrete(parent1[structure][i][type_Fuzzy_Set], parent2[structure][i][type_Fuzzy_Set])\n",
    "        structure1[i][Paramerters_M], structure2[i][Paramerters_M] = crossover_continuous(parent1[structure][i][Paramerters_M], parent2[structure][i][Paramerters_M])\n",
    "        structure1[i][Paramerters_S], structure2[i][Paramerters_S] = crossover_continuous(parent1[structure][i][Paramerters_S], parent2[structure][i][Paramerters_S])\n",
    "    \n",
    "    \n",
    "    rule1 = dict()\n",
    "    rule2 = dict()\n",
    "    \n",
    "    rule1[being], rule2[being] = crossover_discrete(parent1[rule][being], parent2[rule][being])\n",
    "    rule1[not_list], rule2[not_list] = crossover_discrete(parent1[rule][not_list], parent2[rule][not_list])\n",
    "    rule1[term_choice], rule2[term_choice] = crossover_discrete(parent1[rule][term_choice], parent2[rule][term_choice])\n",
    "    \n",
    "    offspring1 = dict()\n",
    "    offspring1[structure] = structure1\n",
    "    offspring1[rule] = rule1\n",
    "    \n",
    "    offspring2 = dict()\n",
    "    offspring2[structure] = structure2\n",
    "    offspring2[rule] = rule2\n",
    "    \n",
    "    return offspring1, offspring2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent2[structure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'structure': [{'linguistic variable': ['low', 'high', 'very low'], 'S': [14.869836785115556, 64.41967866791867, 53.952720515762564], 'M': [-0.8557381452040573, -5.667510879229481, -4.880272426628033], 'fuzzy set': [3, 1, 3]}, {'linguistic variable': ['very low', 'medium', 'very low', 'very high', 'very low'], 'S': [25.357418990937397, 63.92958419520128, 43.60446716179753, 18.185715974366552, 29.30803922728689], 'M': [1.3169017059820032, -7.691180321564525, -2.3163109439255862, 1.2385296484273436, -9.557168271357583], 'fuzzy set': [2, 4, 3, 3, 3]}, {'linguistic variable': ['medium', 'very high', 'low', 'very high'], 'S': [51.54051890860375, 33.41694897775448, 68.84203667651887, 37.77146073098023], 'M': [-5.308719066675653, -10.060265069237776, -6.497100163564631, -8.4670290988363], 'fuzzy set': [1, 1, 1, 3]}, {'linguistic variable': ['very high', 'high', 'high', 'high'], 'S': [15.560478877933734, 66.6658498582636, 68.36569766982821, 52.20479037396023], 'M': [-7.4872559633179545, 1.2757783445731317, -8.354079849173862, 6.27527373382771], 'fuzzy set': [4, 2, 1, 3]}, {'linguistic variable': ['low', 'low', 'very low'], 'S': [51.8321281734655, 47.186941750245076, 10.388224729522515], 'M': [-8.345811033085143, 6.296101264098855, 3.3560810055284307], 'fuzzy set': [1, 2, 3]}], 'rule': {'being': [1, 1, 1, 0, 1], 'not_list': [0, 0, 0, 1, 0], 'term_choice': ['very high', 'high', 'medium', 'high', 'very high']}}\n",
      "{'structure': [{'linguistic variable': ['very high', 'low', 'very low', 'high', 'high'], 'S': [44.12788398482245, 10.077879186267696, 28.785364375800505, 24.26790288483111, 0.8647326285134616], 'M': [-9.290801622472609, -3.635498146300293, 3.6719219017910234, -7.3389061938902405, -2.458415285226799], 'fuzzy set': [2, 3, 2, 1, 3]}, {'linguistic variable': ['medium', 'very low', 'low'], 'S': [11.515502443717502, 47.913891065254305, 32.85470093378219], 'M': [-7.824520581208941, -2.4080394386630815, 0.9680493017745988], 'fuzzy set': [3, 2, 3]}, {'linguistic variable': ['low', 'low', 'low'], 'S': [15.883723893695635, 38.485036629257166, 61.219250890368], 'M': [1.342543173596777, -10.470251337900816, -6.26467787658015], 'fuzzy set': [3, 3, 4]}, {'linguistic variable': ['medium', 'very high', 'very high', 'high'], 'S': [41.95744035682574, 53.80650226779386, 0.7520047766645965, 12.981713044235303], 'M': [-4.000583077949008, 4.8441484424976675, 0.5401087326107081, -3.1109744543652322], 'fuzzy set': [1, 3, 1, 2]}, {'linguistic variable': ['very low', 'medium', 'very high', 'high', 'medium'], 'S': [4.914318646167937, 5.517185065884098, 55.157664573638954, 63.98090722885597, 19.34591870840588], 'M': [3.211348025316747, -3.071802773028736, 5.181429235110954, 0.653096493411816, -5.912593083293197], 'fuzzy set': [4, 4, 4, 3, 1]}], 'rule': {'being': [0, 0, 0, 0, 0], 'not_list': [1, 1, 1, 1, 0], 'term_choice': ['very high', 'high', 'very high', 'very high', 'very low']}}\n",
      "{'structure': [{'linguistic variable': ['low', 'very low', 'high'], 'fuzzy set': [2, 1, 3], 'M': [-7.182035753155471, -6.92105736522505, -2.742223844523269], 'S': [4.366008667663985, 37.69394294883005, 21.04658951864141]}, {'linguistic variable': ['very low', 'very low', 'medium', 'very low', 'low'], 'fuzzy set': [2, 3, 3, 2, 3], 'M': [-6.447468171888103, -7.769886063183957, 1.035669388437785, 1.3169017059820032, -7.691180321564525], 'S': [14.975981580522475, 33.95950218677874, 40.623421749136966, 43.60446716179753]}, {'linguistic variable': ['very high', 'low', 'low', 'low'], 'fuzzy set': [1, 3, 3, 4], 'M': [-3.645903506607546, -10.367754770735056, -7.916441293272262, -6.497100163564631], 'S': [29.123302089401445, 41.748907199093814, 40.36752445590786]}, {'linguistic variable': ['medium', 'very high', 'very high', 'high'], 'fuzzy set': [1, 3, 1, 2], 'M': [-6.393185586079774, 0.724026135601314, -5.05452277625598, -1.4316188750048284], 'S': [4.4541233019818804, 57.02133916541129, 26.827709200633528, 44.519277861109366]}, {'linguistic variable': ['medium', 'high', 'medium'], 'fuzzy set': [4, 4, 3], 'M': [-5.4565212684846705, 2.0638476860835757, -1.4648318283894444], 'S': [16.64377102799233, 26.306174468865677, 6.734944981793702]}], 'rule': {'being': [0, 0, 0, 0, 0], 'not_list': [1, 1, 1, 1, 0], 'term_choice': ['very high', 'high', 'very high', 'very high', 'very low']}}\n",
      "{'structure': [{'linguistic variable': ['very high', 'high', 'low', 'high', 'very low'], 'fuzzy set': [2, 3, 3, 1, 3], 'M': [-2.964504014521195, -6.085359707894671, 1.5338733196862595, -3.635498146300293, -2.458415285226799], 'S': [11.368560745965032, 55.51110009488913, 42.98401018338885, 44.12788398482245, 24.26790288483111]}, {'linguistic variable': ['medium', 'very low', 'very high'], 'fuzzy set': [4, 3, 3], 'M': [-3.6933633532464247, -4.195321646836707, 1.1709095617641574], 'S': [21.896939854132423, 43.26242810576245, 56.160863379846504]}, {'linguistic variable': ['medium', 'very high', 'low'], 'fuzzy set': [1, 1, 3], 'M': [-0.3202723864713306, -10.162761636403536, -6.815265682144187], 'S': [55.60245848081306, 48.2766483387671, 54.26867541221462]}, {'linguistic variable': ['very high', 'high', 'high', 'high'], 'fuzzy set': [4, 2, 1, 3], 'M': [-4.205044831603413, 1.0918609415825258, 1.544591369579785, 3.7063095308835305], 'S': [11.858360352616451, 63.45101296064617, 54.51970151342998, 49.642952869676606]}, {'linguistic variable': ['very low', 'very high', 'low', 'low', 'very low'], 'fuzzy set': [4, 1, 1, 2, 3], 'M': [0.3220582607162745, 4.885350071427095, 1.749110060889139, 5.181429235110954, -5.912593083293197], 'S': [40.102675791641104, 40.226685989785274, 9.17046481361291, 55.157664573638954, 63.98090722885597]}], 'rule': {'being': [1, 1, 1, 0, 1], 'not_list': [0, 0, 0, 1, 0], 'term_choice': ['very high', 'high', 'medium', 'high', 'very high']}}\n",
      "[4.366008667663985, 37.69394294883005, 21.04658951864141]\n",
      "[11.368560745965032, 55.51110009488913, 42.98401018338885, 44.12788398482245, 24.26790288483111]\n"
     ]
    }
   ],
   "source": [
    "print(parent1)\n",
    "print(parent2)\n",
    "child1, child2 = crossover(parent1, parent2)\n",
    "print(child1)\n",
    "print(child2)\n",
    "print(child1[structure][0][Paramerters_S])\n",
    "print(child2[structure][0][Paramerters_S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation_(parent):\n",
    "    offspring = []\n",
    "    for i in range(len(parent)):\n",
    "        if random.ranint() < mutation_rate:\n",
    "            offspring.append(parent[i] + random.uniform(-1, 1) * mutation_step)\n",
    "        else:\n",
    "            offspring.append(parent[i])\n",
    "    return offspring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
