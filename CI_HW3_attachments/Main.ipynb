{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linguistic_variable = \"linguistic variable\"\n",
    "Paramerters_S = \"S\"\n",
    "Paramerters_M = \"M\"\n",
    "type_Fuzzy_Set = \"fuzzy set\"\n",
    "rule = \"rule\"   \n",
    "structure = 'structure'\n",
    "being = 'being'\n",
    "not_list = 'not_list'\n",
    "term_choice = 'term_choice'\n",
    "elements = 'elements'\n",
    "fitness = 'fitness'\n",
    "gens = 'gens'\n",
    "gen_num = 10\n",
    "\n",
    "Max_S = 70   # 2 * 35   # calcualte the database\n",
    "Min_S = 0\n",
    "Max_M = 7    # 2*5\n",
    "Min_M = -11  # 2*-5\n",
    "element_num = 10\n",
    "max_num_of_features = 5\n",
    "linguistic = [\"very low\", \"low\", \"medium\", \"high\", \"very high\"]\n",
    "\n",
    "crossover_rate = 0.8\n",
    "mutation_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a list of chromosomes.\n",
    "def create_chromosomes(num_chromosomes):\n",
    "    # Initialize an empty list to store the chromosomes.\n",
    "    chromosomes = []\n",
    "    \n",
    "    # For each chromosome:\n",
    "    for i in range(num_chromosomes):\n",
    "        chro = dict()\n",
    "        chro[gens] = []\n",
    "        chro[fitness] = 0\n",
    "        for _ in range(gen_num):\n",
    "            # Initialize an empty dictionary to store this chromosome's genetic material.\n",
    "            gen = dict()\n",
    "            gen[structure] = []\n",
    "            # For each genetic element (gene) in the chromosome:\n",
    "            for _ in range(max_num_of_features):\n",
    "                # Initialize an empty dictionary to store this gene's features (linguistic variable, parameter S, parameter M, and type of fuzzy set).\n",
    "                struct = dict()\n",
    "                # Generate a random number between 3 and 5 to determine the number of linguistic variables in this feature.\n",
    "                num_feature = random.randint(3, 5)\n",
    "                # For each linguistic variable in this feature, randomly choose one from the set of possible linguistic variables and add it to the list of linguistic variables in this feature.\n",
    "                struct[linguistic_variable] = [random.choice(linguistic) for i in range(num_feature)]\n",
    "                # For each parameter S in this feature, randomly generate a floating-point number between Min_S and Max_S and add it to the list of S parameters in this feature.\n",
    "                struct[Paramerters_S] = [random.uniform(Min_S, Max_S) for i in range(num_feature)]\n",
    "                # For each parameter M in this feature, randomly generate a floating-point number between Min_M and Max_M and add it to the list of M parameters in this feature.\n",
    "                struct[Paramerters_M] = [random.uniform(Min_M, Max_M) for i in range(num_feature)]\n",
    "                # For each type of fuzzy set in this feature, randomly generate an integer between 1 and 4 and add it to the list of fuzzy set types in this feature.\n",
    "                struct[type_Fuzzy_Set] = [random.randint(1, 4) for i in range(num_feature)]\n",
    "                # Add the current gene (with its features) to this chromosome.\n",
    "                gen[structure].append(struct)\n",
    "            \n",
    "            # Initialize an empty dictionary to store the rule for this chromosome's genetic material.\n",
    "            gen_rule = dict()\n",
    "            # For each genetic element (gene) in the chromosome:\n",
    "            gen_rule[being] = [random.choice([0, 1]) for i in range(max_num_of_features)]     # 1 ==> be   0 ==> not be\n",
    "            gen_rule[not_list] = [random.choice([0, 1]) for i in range(max_num_of_features)]  # 1 ==> NOT   0 ==> self\n",
    "            gen_rule[term_choice] = [random.choice(linguistic) for i in range(max_num_of_features)]   # which term?\n",
    "            # Add the rule to this chromosome.\n",
    "            gen[rule] = gen_rule  \n",
    "            # Add this chromosome (with its genetic material and rule) to the list of chromosomes.\n",
    "            chro[gens].append(gen)\n",
    "        \n",
    "        chromosomes.append(chro)\n",
    "    # Return the list of chromosomes.\n",
    "    return chromosomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "chro = create_chromosomes2(2)\n",
    "print(len(chro[0]))\n",
    "# print(chro[0][structure][0][linguistic_variable])\n",
    "# print(chro[1][structure][0])\n",
    "\n",
    "parent1 = chro[0]\n",
    "parent2 = chro[1]\n",
    "\n",
    "#print(chro[0][structure][0][Paramerters_S])\n",
    "#print(chro[0][structure][1][Paramerters_S])\n",
    "# print(parent1)\n",
    "# print(parent2)\n",
    "# parent1_linguistic = chro[0][structure][0][linguistic_variable]\n",
    "# parent2_linguistic = chro[1][structure][0][linguistic_variable]\n",
    "\n",
    "# parent1_S = chro[0][structure][0][Paramerters_S]\n",
    "# parent2_S = chro[1][structure][0][Paramerters_S]\n",
    "\n",
    "# parent1_M = chro[0][structure][0][Paramerters_M]\n",
    "# parent2_M = chro[1][structure][0][Paramerters_M]\n",
    "\n",
    "# parent1_fuzzy = chro[0][structure][0][type_Fuzzy_Set]\n",
    "# parent2_fuzzy = chro[1][structure][0][type_Fuzzy_Set]\n",
    "\n",
    "# parent1_bein = chro[0][rule][being]\n",
    "# parent2_bein = chro[1][rule][being]\n",
    "\n",
    "# parent1_not_list = chro[0][rule][not_list]\n",
    "# parent2_not_list = chro[1][rule][not_list]\n",
    "\n",
    "# parent1_term_choice = chro[0][rule][term_choice]\n",
    "# parent2_term_choice = chro[1][rule][term_choice]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in two parents (sequences) and creates two offsprings by performing a continuous crossover.\n",
    "def crossover_continuous(parent1, parent2):    \n",
    "    # Set the alpha value for the crossover.\n",
    "    alpha = 0.25\n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    # If the first sequence is longer than the second one:\n",
    "    if len(parent1) > len(parent2):\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent1)), len(parent2))\n",
    "        # For each index in the shorter parent: if the corresponding element in the longer parent is greater, perform a crossover calculation using alpha and add the results to offspring1 and offspring2. Otherwise, perform the calculation using the reverse order and add the results to offspring1 and offspring2.\n",
    "        for i in range(len(parent2)):\n",
    "            if parent2[i] > parent1[indexes[i]]:\n",
    "                distance = parent2[i] - parent1[indexes[i]]\n",
    "                offspring1.append(parent1[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent2[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent1[indexes[i]] - parent2[i]\n",
    "                offspring1.append(parent2[i] + alpha * distance)\n",
    "                offspring2.append(parent1[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        # Add the remaining elements of the longer parent to the first offspring.     \n",
    "        temp = [item for item in [_ for _ in range(len(parent2))] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "            offspring1.append(parent1[temp[i]])\n",
    "        \n",
    "    # If the second sequence is longer than or the same length as the first one:\n",
    "    else:\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent2)), len(parent1))\n",
    "        # For each index in the shorter parent: if the corresponding element in the longer parent is greater, perform a crossover calculation using alpha and add the results to offspring1 and offspring2. Otherwise, perform the calculation using the reverse order and add the results to offspring1 and offspring2.\n",
    "        for i in range(len(parent1)):\n",
    "            if parent1[i] > parent2[indexes[i]]:\n",
    "                distance = parent1[i] - parent2[indexes[i]]\n",
    "                offspring1.append(parent2[indexes[i]] + alpha * distance)\n",
    "                offspring2.append(parent1[i] - alpha * distance)\n",
    "            else:\n",
    "                distance = parent2[indexes[i]] - parent1[i]\n",
    "                offspring1.append(parent1[i] + alpha * distance)\n",
    "                offspring2.append(parent2[indexes[i]] - alpha * distance)\n",
    "                \n",
    "        # Add the remaining elements of the longer parent to the second offspring. \n",
    "        temp = [item for item in [_ for _ in range(len(parent2))] if item not in indexes]\n",
    "        for i in range(len(temp)):\n",
    "            offspring2.append(parent2[temp[i]])\n",
    "    \n",
    "    # Return the two new offspring.\n",
    "    return offspring1, offspring2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in two parents (sequences) and creates two offsprings by performing a discrete crossover.\n",
    "def crossover_discrete(parent1, parent2):   \n",
    "    offspring1 = []\n",
    "    offspring2 = []\n",
    "    # If the first sequence is longer than the second one:\n",
    "    if len(parent1) > len(parent2):\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent1)), len(parent2))\n",
    "        # For each index in parent1: if it's in indexes, add the corresponding element to offspring2. Otherwise, add it to offspring1. \n",
    "        for i in range(len(parent1)):\n",
    "            if i in indexes:\n",
    "                offspring2.append(parent1[i])\n",
    "            else:\n",
    "                offspring1.append(parent1[i])\n",
    "        # Add all of parent2 to offspring1.\n",
    "        offspring1.extend(parent2)     \n",
    "    # If the second sequence is longer than or the same length as the first one:\n",
    "    else:\n",
    "        # Generate a list of random indexes for the shorter sequence.\n",
    "        indexes = random.sample(range(len(parent2)), len(parent1))\n",
    "        # For each index in parent2: if it's in indexes, add the corresponding element to offspring1. Otherwise, add it to offspring2. \n",
    "        for i in range(len(parent2)):\n",
    "            if i in indexes:\n",
    "                offspring1.append(parent2[i])\n",
    "            else:\n",
    "                offspring2.append(parent2[i])\n",
    "        # Add all of parent1 to offspring2.\n",
    "        offspring2.extend(parent1)\n",
    "    \n",
    "    # Return the two new offspring.\n",
    "    return offspring1, offspring2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover_element(parent1, parent2):\n",
    "    structure1 = [dict() for i in range(max_num_of_features)]\n",
    "    structure2 = [dict() for i in range(max_num_of_features)]\n",
    "    \n",
    "    for i in range(max_num_of_features):\n",
    "        structure1[i][linguistic_variable], structure2[i][linguistic_variable] = crossover_discrete(parent1[structure][i][linguistic_variable], parent2[structure][i][linguistic_variable])\n",
    "        structure1[i][type_Fuzzy_Set], structure2[i][type_Fuzzy_Set] = crossover_discrete(parent1[structure][i][type_Fuzzy_Set], parent2[structure][i][type_Fuzzy_Set])\n",
    "        structure1[i][Paramerters_M], structure2[i][Paramerters_M] = crossover_continuous(parent1[structure][i][Paramerters_M], parent2[structure][i][Paramerters_M])\n",
    "        structure1[i][Paramerters_S], structure2[i][Paramerters_S] = crossover_continuous(parent1[structure][i][Paramerters_S], parent2[structure][i][Paramerters_S])\n",
    "    \n",
    "    \n",
    "    rule1 = dict()\n",
    "    rule2 = dict()\n",
    "    \n",
    "    rule1[being], rule2[being] = crossover_discrete(parent1[rule][being], parent2[rule][being])\n",
    "    rule1[not_list], rule2[not_list] = crossover_discrete(parent1[rule][not_list], parent2[rule][not_list])\n",
    "    rule1[term_choice], rule2[term_choice] = crossover_discrete(parent1[rule][term_choice], parent2[rule][term_choice])\n",
    "    \n",
    "    offspring1 = dict()\n",
    "    offspring1[structure] = structure1\n",
    "    offspring1[rule] = rule1\n",
    "    \n",
    "    offspring2 = dict()\n",
    "    offspring2[structure] = structure2\n",
    "    offspring2[rule] = rule2\n",
    "    \n",
    "    return offspring1, offspring2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(chromosomes):\n",
    "    new_population = []\n",
    "    \n",
    "    chromosomes.sort(key = lambda x: x[fitness])\n",
    "    size = int(crossover_rate * len(chromosomes) / 2)\n",
    "    child1 = dict()\n",
    "    child2 = dict()\n",
    "    for i in range(size):\n",
    "        temp1 = dict()\n",
    "        temp2 = dict()\n",
    "        for j in range(gen_num):\n",
    "            temp1, temp2 = crossover_element(chromosomes[2 * i][gens][j], chromosomes[2 * i + 1][gens][j])\n",
    "            child1[gens].append(temp1)\n",
    "            child2[gens].append(temp2)\n",
    "        \n",
    "        child1[fitness] = 0\n",
    "        child2[fitness] = 0\n",
    "        \n",
    "        new_population.append(child1)\n",
    "        new_population.append(child2)\n",
    "    \n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parent2[structure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'structure': [{'linguistic variable': ['low', 'high', 'very low'], 'S': [14.869836785115556, 64.41967866791867, 53.952720515762564], 'M': [-0.8557381452040573, -5.667510879229481, -4.880272426628033], 'fuzzy set': [3, 1, 3]}, {'linguistic variable': ['very low', 'medium', 'very low', 'very high', 'very low'], 'S': [25.357418990937397, 63.92958419520128, 43.60446716179753, 18.185715974366552, 29.30803922728689], 'M': [1.3169017059820032, -7.691180321564525, -2.3163109439255862, 1.2385296484273436, -9.557168271357583], 'fuzzy set': [2, 4, 3, 3, 3]}, {'linguistic variable': ['medium', 'very high', 'low', 'very high'], 'S': [51.54051890860375, 33.41694897775448, 68.84203667651887, 37.77146073098023], 'M': [-5.308719066675653, -10.060265069237776, -6.497100163564631, -8.4670290988363], 'fuzzy set': [1, 1, 1, 3]}, {'linguistic variable': ['very high', 'high', 'high', 'high'], 'S': [15.560478877933734, 66.6658498582636, 68.36569766982821, 52.20479037396023], 'M': [-7.4872559633179545, 1.2757783445731317, -8.354079849173862, 6.27527373382771], 'fuzzy set': [4, 2, 1, 3]}, {'linguistic variable': ['low', 'low', 'very low'], 'S': [51.8321281734655, 47.186941750245076, 10.388224729522515], 'M': [-8.345811033085143, 6.296101264098855, 3.3560810055284307], 'fuzzy set': [1, 2, 3]}], 'rule': {'being': [1, 1, 1, 0, 1], 'not_list': [0, 0, 0, 1, 0], 'term_choice': ['very high', 'high', 'medium', 'high', 'very high']}}\n",
      "{'structure': [{'linguistic variable': ['very high', 'low', 'very low', 'high', 'high'], 'S': [44.12788398482245, 10.077879186267696, 28.785364375800505, 24.26790288483111, 0.8647326285134616], 'M': [-9.290801622472609, -3.635498146300293, 3.6719219017910234, -7.3389061938902405, -2.458415285226799], 'fuzzy set': [2, 3, 2, 1, 3]}, {'linguistic variable': ['medium', 'very low', 'low'], 'S': [11.515502443717502, 47.913891065254305, 32.85470093378219], 'M': [-7.824520581208941, -2.4080394386630815, 0.9680493017745988], 'fuzzy set': [3, 2, 3]}, {'linguistic variable': ['low', 'low', 'low'], 'S': [15.883723893695635, 38.485036629257166, 61.219250890368], 'M': [1.342543173596777, -10.470251337900816, -6.26467787658015], 'fuzzy set': [3, 3, 4]}, {'linguistic variable': ['medium', 'very high', 'very high', 'high'], 'S': [41.95744035682574, 53.80650226779386, 0.7520047766645965, 12.981713044235303], 'M': [-4.000583077949008, 4.8441484424976675, 0.5401087326107081, -3.1109744543652322], 'fuzzy set': [1, 3, 1, 2]}, {'linguistic variable': ['very low', 'medium', 'very high', 'high', 'medium'], 'S': [4.914318646167937, 5.517185065884098, 55.157664573638954, 63.98090722885597, 19.34591870840588], 'M': [3.211348025316747, -3.071802773028736, 5.181429235110954, 0.653096493411816, -5.912593083293197], 'fuzzy set': [4, 4, 4, 3, 1]}], 'rule': {'being': [0, 0, 0, 0, 0], 'not_list': [1, 1, 1, 1, 0], 'term_choice': ['very high', 'high', 'very high', 'very high', 'very low']}}\n",
      "{'structure': [{'linguistic variable': ['low', 'very low', 'high'], 'fuzzy set': [2, 1, 3], 'M': [-7.182035753155471, -6.92105736522505, -2.742223844523269], 'S': [4.366008667663985, 37.69394294883005, 21.04658951864141]}, {'linguistic variable': ['very low', 'very low', 'medium', 'very low', 'low'], 'fuzzy set': [2, 3, 3, 2, 3], 'M': [-6.447468171888103, -7.769886063183957, 1.035669388437785, 1.3169017059820032, -7.691180321564525], 'S': [14.975981580522475, 33.95950218677874, 40.623421749136966, 43.60446716179753]}, {'linguistic variable': ['very high', 'low', 'low', 'low'], 'fuzzy set': [1, 3, 3, 4], 'M': [-3.645903506607546, -10.367754770735056, -7.916441293272262, -6.497100163564631], 'S': [29.123302089401445, 41.748907199093814, 40.36752445590786]}, {'linguistic variable': ['medium', 'very high', 'very high', 'high'], 'fuzzy set': [1, 3, 1, 2], 'M': [-6.393185586079774, 0.724026135601314, -5.05452277625598, -1.4316188750048284], 'S': [4.4541233019818804, 57.02133916541129, 26.827709200633528, 44.519277861109366]}, {'linguistic variable': ['medium', 'high', 'medium'], 'fuzzy set': [4, 4, 3], 'M': [-5.4565212684846705, 2.0638476860835757, -1.4648318283894444], 'S': [16.64377102799233, 26.306174468865677, 6.734944981793702]}], 'rule': {'being': [0, 0, 0, 0, 0], 'not_list': [1, 1, 1, 1, 0], 'term_choice': ['very high', 'high', 'very high', 'very high', 'very low']}}\n",
      "{'structure': [{'linguistic variable': ['very high', 'high', 'low', 'high', 'very low'], 'fuzzy set': [2, 3, 3, 1, 3], 'M': [-2.964504014521195, -6.085359707894671, 1.5338733196862595, -3.635498146300293, -2.458415285226799], 'S': [11.368560745965032, 55.51110009488913, 42.98401018338885, 44.12788398482245, 24.26790288483111]}, {'linguistic variable': ['medium', 'very low', 'very high'], 'fuzzy set': [4, 3, 3], 'M': [-3.6933633532464247, -4.195321646836707, 1.1709095617641574], 'S': [21.896939854132423, 43.26242810576245, 56.160863379846504]}, {'linguistic variable': ['medium', 'very high', 'low'], 'fuzzy set': [1, 1, 3], 'M': [-0.3202723864713306, -10.162761636403536, -6.815265682144187], 'S': [55.60245848081306, 48.2766483387671, 54.26867541221462]}, {'linguistic variable': ['very high', 'high', 'high', 'high'], 'fuzzy set': [4, 2, 1, 3], 'M': [-4.205044831603413, 1.0918609415825258, 1.544591369579785, 3.7063095308835305], 'S': [11.858360352616451, 63.45101296064617, 54.51970151342998, 49.642952869676606]}, {'linguistic variable': ['very low', 'very high', 'low', 'low', 'very low'], 'fuzzy set': [4, 1, 1, 2, 3], 'M': [0.3220582607162745, 4.885350071427095, 1.749110060889139, 5.181429235110954, -5.912593083293197], 'S': [40.102675791641104, 40.226685989785274, 9.17046481361291, 55.157664573638954, 63.98090722885597]}], 'rule': {'being': [1, 1, 1, 0, 1], 'not_list': [0, 0, 0, 1, 0], 'term_choice': ['very high', 'high', 'medium', 'high', 'very high']}}\n",
      "[4.366008667663985, 37.69394294883005, 21.04658951864141]\n",
      "[11.368560745965032, 55.51110009488913, 42.98401018338885, 44.12788398482245, 24.26790288483111]\n"
     ]
    }
   ],
   "source": [
    "print(parent1)\n",
    "print(parent2)\n",
    "child1, child2 = crossover(parent1, parent2)\n",
    "print(child1)\n",
    "print(child2)\n",
    "print(child1[structure][0][Paramerters_S])\n",
    "print(child2[structure][0][Paramerters_S])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
